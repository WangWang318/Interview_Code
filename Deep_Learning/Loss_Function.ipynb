{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44719975",
   "metadata": {},
   "source": [
    "## 均方误差 MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250ae100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss:  0.2875000834465027\n",
      "gradient of y:  tensor([-0.2500,  0.2500,  0.0500,  0.4000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "y_pred = torch.tensor([2.5, 0.0, 2.1, 7.8], requires_grad=True)\n",
    "y_true = torch.tensor([3.0, -0.5, 2.0, 7.0])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(y_pred, y_true)\n",
    "print(\"MSE Loss: \", loss.item())\n",
    "\n",
    "loss.backward()\n",
    "print(\"gradient of y: \", y_pred.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2078fb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss:  0.2875000834465027\n",
      "gradient manual:  tensor([-0.2500,  0.2500,  0.0500,  0.4000], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 手写\n",
    "diff = y_pred - y_true\n",
    "loss = torch.mean(diff**2)\n",
    "\n",
    "print(\"MSE Loss: \", loss.item())\n",
    "\n",
    "n = y_pred.shape[0]\n",
    "grad_manual = (2.0/n) * (y_pred - y_true)\n",
    "\n",
    "print(\"gradient manual: \", grad_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506eda5e",
   "metadata": {},
   "source": [
    "## 交叉熵\n",
    "二分类 $Loss = - \\frac{1}{n}\\sum_{i = 1}^{n}[y_i \\log(\\sigma(x_i)) + (1 - y_i)\\log(1 - \\sigma(x_i))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4abb0cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCELoss:  0.2642763555049896\n",
      "gradient:  tensor([-0.4990,  0.4335, -0.3784])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "probs = torch.tensor([0.668, 0.231, 0.881], requires_grad=True)\n",
    "labels = torch.tensor([1, 0, 1], dtype=torch.float32)\n",
    "criterion = nn.BCELoss()\n",
    "loss = criterion(probs, labels)\n",
    "\n",
    "print(\"BCELoss: \", loss.item())\n",
    "\n",
    "loss.backward()\n",
    "print(\"gradient: \", probs.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3190b6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross Entropy Loss: 0.2644655108451843\n",
      "logits 的梯度： tensor([-0.1106,  0.0772, -0.0397])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设模型输出的是 logits（未经过 Sigmoid）\n",
    "logits = torch.tensor([0.7, -1.2, 2.0], requires_grad=True)  # shape: [batch_size]\n",
    "labels = torch.tensor([1.0, 0.0, 1.0])  # shape: [batch_size]\n",
    "\n",
    "# 使用 BCEWithLogitsLoss（自动对 logits 做 Sigmoid）\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(\"Binary Cross Entropy Loss:\", loss.item())\n",
    "\n",
    "# 反向传播\n",
    "loss.backward()\n",
    "print(\"logits 的梯度：\", logits.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff87346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.2642762362957001\n",
      "Gradient:  tensor([-0.4990,  0.4335, -0.3784], grad_fn=<DivBackward0>)\n",
      "Autograd gradient: tensor([-0.4990,  0.4335, -0.3784])\n"
     ]
    }
   ],
   "source": [
    "# 手写交叉熵\n",
    "# 模拟一组预测概率（已过 Sigmoid）和真实标签\n",
    "y_pred = torch.tensor([0.668, 0.231, 0.881], requires_grad=True)  # 模型预测的概率\n",
    "y_true = torch.tensor([1.0, 0.0, 1.0])  # 标签\n",
    "n = y_pred.shape[0]\n",
    "epsilon = 1e-7\n",
    "loss = -torch.mean(y_true * torch.log(y_pred + epsilon) + (1 - y_true) * torch.log(1 - y_pred + epsilon))\n",
    "print(\"Loss: \", loss.item())\n",
    "\n",
    "gradient_manual = -(y_true/y_pred - (1 - y_true)/(1 - y_pred)) / n\n",
    "print(\"Gradient: \", gradient_manual)\n",
    "\n",
    "# 自动求导\n",
    "# loss.backward()\n",
    "# print(\"Autograd gradient:\", y_pred.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "486a72ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross Entropy Loss: 0.2644655704498291\n",
      "gradient_manual:  tensor([-0.1106,  0.0772, -0.0397], grad_fn=<DivBackward0>)\n",
      "logits 的梯度： tensor([-0.1106,  0.0772, -0.0397])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设模型输出的是 logits（未经过 Sigmoid）\n",
    "logits = torch.tensor([0.7, -1.2, 2.0], requires_grad=True)  # shape: [batch_size]\n",
    "labels = torch.tensor([1.0, 0.0, 1.0])  # shape: [batch_size]\n",
    "epsilon = 0\n",
    "loss = -torch.mean(y_true * torch.log(torch.sigmoid(logits) + epsilon) + (1 - y_true) * torch.log(1 - torch.sigmoid(logits) + epsilon))\n",
    "\n",
    "print(\"Binary Cross Entropy Loss:\", loss.item())\n",
    "n = logits.shape[0]\n",
    "y_pred = torch.sigmoid(logits)\n",
    "gradient_manual = - (y_true - y_pred)/n\n",
    "\n",
    "print(\"gradient_manual: \", gradient_manual)\n",
    "# 反向传播\n",
    "loss.backward()\n",
    "print(\"logits 的梯度：\", logits.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389bf853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mappo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
